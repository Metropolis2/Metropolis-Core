// Copyright 2022 Lucas Javaudin
//
// Licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International
// https://creativecommons.org/licenses/by-nc-nd/4.0/legalcode

//! Everything related to simulation parameters.
use schemars::JsonSchema;
use serde_derive::{Deserialize, Serialize};
use ttf::TTFNum;

use crate::learning::LearningModel;
use crate::network::{NetworkParameters, NetworkWeights};
use crate::simulation::results::AgentResults;
use crate::stop::StopCriterion;
use crate::units::{Interval, Time};

const fn default_iteration_counter() -> u32 {
    1
}

const fn default_update_ratio() -> f64 {
    1.0
}

/// Set of parameters used to control how a [Simulation](crate::simulation::Simulation) is run.
#[derive(Clone, Debug, Deserialize, Serialize, JsonSchema)]
#[serde(bound(deserialize = "T: TTFNum"))]
#[schemars(example = "crate::schema::example_parameters")]
pub struct Parameters<T> {
    /// Time interval used to restrict the travel-time functions of the edges.
    ///
    /// The departure-time intervals of the agents must be included in this interval.
    ///
    /// Agents can still travel on the network when the period is exceeded but the edges' travel
    /// times are no longer recorded.
    /// The departure time chosen by any agent must be such that the expected arrival time is
    /// earlier than the end of the period.
    pub period: Interval<T>,
    /// Initial iteration counter to use for the simulation.
    ///
    /// This is useful when running a simulation "step-by-step" (i.e., the input is modified
    /// partially from one iteration to another) so that, for example, the coefficients for the
    /// learning model are correctly computed.
    #[serde(default = "default_iteration_counter")]
    #[validate(range(min = 1))]
    pub init_iteration_counter: u32,
    /// Set of parameters for the network.
    pub network: NetworkParameters<T>,
    /// Learning model used to update the values between two iterations.
    #[serde(default)]
    pub learning_model: LearningModel<T>,
    /// Set of stopping criteria used to decide when the iterative process should stop.
    pub stopping_criteria: Vec<StopCriterion<T>>,
    /// Share of agents that can update their pre-day choices at each iteration.
    #[serde(default = "default_update_ratio")]
    #[validate(range(min = 0.0, max = 1.0))]
    pub update_ratio: f64,
    /// Random seed used for all the draws.
    ///
    /// If `null`, the seed is generated by entropy.
    #[serde(default)]
    pub random_seed: Option<u64>,
    /// Number of threads to use for parallel tasks.
    ///
    /// Default (0) is to use all the threads of the CPU.
    #[serde(default)]
    pub nb_threads: usize,
}

impl<T: TTFNum> Default for Parameters<T> {
    fn default() -> Self {
        Self {
            period: Interval([Time(T::zero()), Time(T::infinity())]),
            init_iteration_counter: 1,
            network: Default::default(),
            learning_model: Default::default(),
            stopping_criteria: vec![StopCriterion::MaxIteration(1)],
            update_ratio: 1.0,
            random_seed: None,
            nb_threads: 0,
        }
    }
}

impl<T: TTFNum> Parameters<T> {
    /// Returns `true` if the Simulation must be stopped.
    ///
    /// The Simulation is stopped if at least one of the stopping criteria is active.
    pub fn stop(
        &self,
        iteration_counter: u32,
        results: &AgentResults<T>,
        prev_results: Option<&AgentResults<T>>,
    ) -> bool {
        self.stopping_criteria
            .iter()
            .any(|c| c.stop(iteration_counter, results, prev_results))
    }

    /// Returns the new [NetworkWeights] given the old weights and the simulated weights.
    pub fn learn(
        &self,
        old_weights: &NetworkWeights<T>,
        weights: &NetworkWeights<T>,
        iteration_counter: u32,
    ) -> NetworkWeights<T> {
        // At this point, the iteration counter has not been increment yet.
        let mut new_weights =
            self.learning_model
                .learn(old_weights, weights, iteration_counter + 1);
        new_weights.simplify(&self.network);
        new_weights
    }
}
